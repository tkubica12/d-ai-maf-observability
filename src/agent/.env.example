# Environment variables for MAF agents

# Azure AI Configuration
# For direct LLM access (Approach 1) - Azure OpenAI Responses API
# Endpoint should be the base Azure OpenAI endpoint (e.g., https://<resource>.openai.azure.com)
AI_ENDPOINT=https://mafobsdevaidnp0cy.openai.azure.com

# For Foundry Agent Service (Approach 2) 
PROJECT_ENDPOINT=https://mafobsdevaidnp0cy.services.ai.azure.com/api/projects/mafobs-project

# Model configuration
MODEL_NAME=gpt-5-nano
MODEL_DEPLOYMENT=gpt-5-nano

# Tool server URLs (with correct ports)
API_SERVER_URL=http://localhost:8000
MCP_SERVER_URL=http://localhost:8001/mcp

# Common configuration
HOST=0.0.0.0
PORT=8002

# Optional: Azure authentication (if not using default credentials)
# AZURE_TENANT_ID=your-tenant-id
# AZURE_CLIENT_ID=your-client-id

# Optional: OpenTelemetry configuration (comment out to disable observability)
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
# OTEL_SERVICE_NAME=agent  
# ENABLE_SENSITIVE_DATA=true